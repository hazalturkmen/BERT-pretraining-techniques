# Simultaneous-pretraining-BERT
This repo includes  python scripts to implement Simultaneous pre-training approach [1] to enhance BioBERTurk language models
# References
[1]Wada, S., Takeda, T., Manabe, S., Konishi, S., Kamohara, J., & Matsumura, Y. (2020). Pre-training technique to localize medical bert and enhance biomedical bert. arXiv preprint arXiv:2005.07202.
