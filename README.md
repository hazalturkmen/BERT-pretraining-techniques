# A Pipeline Of Simultaneous pretraining with amplified vocabulary Bert On Google TPU
A tutorial of pertaining Bert on your own dataset using google TPU to implement Simultaneous pre-training with amplified vocabulary approach [1] 


# Introduction


# References
[1]Wada, S., Takeda, T., Manabe, S., Konishi, S., Kamohara, J., & Matsumura, Y. (2020). Pre-training technique to localize medical bert and enhance biomedical bert. arXiv preprint arXiv:2005.07202.


# Acknowledgements
We would like to acknowledge the support we received from the TPU Research Cloud(TRC) team in providing access to TPUv3 units.
